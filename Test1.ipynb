{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9qnINu0VTt8a"
   },
   "source": [
    "## **Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-21T07:28:45.138091Z",
     "start_time": "2021-02-21T07:28:45.133087Z"
    },
    "id": "8BEr31BsugTD"
   },
   "outputs": [],
   "source": [
    "# %%capture cap\n",
    "## Call pip install on 1st time only\n",
    "# pip install geneticalgorithm\n",
    "# pip install import-ipynb\n",
    "# pip install git+https://github.com/hyperopt/hyperopt-sklearn.git\n",
    "# pip install platypus-opt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-21T07:28:48.200996Z",
     "start_time": "2021-02-21T07:28:45.145094Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9gmaL2jdDguo",
    "outputId": "8c68f3c6-99a4-4193-bccf-064ad3b1c3c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARN: OMP_NUM_THREADS=None =>\n",
      "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest,SelectFromModel,RFE,chi2,mutual_info_classif,f_classif\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing,metrics\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,ExtraTreesClassifier\n",
    "from sklearn.model_selection import KFold,StratifiedKFold\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score\n",
    "from geneticalgorithm import geneticalgorithm as ga\n",
    "from sklearn.metrics import accuracy_score,roc_auc_score,auc,roc_curve\n",
    "import math\n",
    "\n",
    "import import_ipynb\n",
    "# from FuzzyTools import FRBCS\n",
    "\n",
    "from hpsklearn import HyperoptEstimator, any_classifier, any_preprocessing, extra_trees,random_forest\n",
    "from hyperopt import tpe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H17noAJObOO7"
   },
   "source": [
    "# **Parameter Settings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-21T07:28:48.209998Z",
     "start_time": "2021-02-21T07:28:48.202993Z"
    },
    "id": "vyOBJru1a2MY"
   },
   "outputs": [],
   "source": [
    "Path_data ='./data_myron/GSE89843_count_matrix_tmm.csv'\n",
    "Path_label ='./data_myron/GSE89843_patients_characteristics.csv'\n",
    "\n",
    "n_folds=5\n",
    "max_Evals=50000\n",
    "n_final_features_to_select=5\n",
    "\n",
    "metric_of_KBest = mutual_info_classif   #f_classif \n",
    "k_KBest=100  #1000\n",
    "\n",
    "step_REF=1\n",
    "\n",
    "\n",
    "####for SelectFromModel and RFE\n",
    "# estimator=RandomForestClassifier()\n",
    "# estimator=AdaBoostClassifier()\n",
    "estimator=LogisticRegression() \n",
    "# estimator=ExtraTreesClassifier(n_estimators=50)\n",
    "\n",
    "clf = LogisticRegression( solver='sag', multi_class='multinomial',penalty='l2')   #penalty='none'\n",
    "# clf = AdaBoostClassifier()  # n_estimators=100\n",
    "n_estimators=100\n",
    "# clf = RandomForestClassifier(n_estimators)\n",
    "\n",
    "algorithm_param = {'max_num_iteration': 100,'population_size':10,'mutation_probability':0.1,\\\n",
    "'elit_ratio': 0,'crossover_probability': 0.5,'parents_portion': 0.3,'crossover_type':'one_point','max_iteration_without_improv':None}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ysxnCrczi6Yg"
   },
   "source": [
    "# **Methods and Classes**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZJRbD9QCTCr0"
   },
   "source": [
    "**Result, PrintResult,MakeDF**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-21T07:28:48.414055Z",
     "start_time": "2021-02-21T07:28:48.213000Z"
    },
    "id": "pW3GH0O-swu8"
   },
   "outputs": [],
   "source": [
    "class Result:\n",
    "    Score_train,Score_test,AUC_train,AUC_test,n_selceted_feature,n_Rules,state=0,0,0,0,0,0,''\n",
    "    def __init__(self, Score_train=0, Score_test=0,AUC_train=0,AUC_test=0,n_selceted_feature=0,n_Rules=0,state=''):\n",
    "        self.Score_train,self.Score_test,self.AUC_train,self.AUC_test,self.n_selceted_feature,self.n_Rules,self.state=Score_train,Score_test,AUC_train,AUC_test,n_selceted_feature,n_Rules,state\n",
    "\n",
    "def PrintResults(results, state,DF_results):\n",
    "  # print('\\n'+ state + '....')\n",
    "    scores = [r.Score_train for r in results if r.state==state]\n",
    "    if len(scores)==0:\n",
    "        S1=np.nan\n",
    "    else:\n",
    "        S1=sum(scores)/len(scores)\n",
    "    scores = [r.Score_test for r in results if r.state==state]\n",
    "    if len(scores)==0: \n",
    "        S2=np.nan \n",
    "    else:\n",
    "        S2=sum(scores)/len(scores)\n",
    "    scores = [r.AUC_train for r in results if r.state==state]\n",
    "    if len(scores)==0:\n",
    "        S3=np.nan\n",
    "    else:\n",
    "        S3=sum(scores)/len(scores)\n",
    "    scores = [r.AUC_test for r in results if r.state==state]\n",
    "    if len(scores)==0:\n",
    "        S4=np.nan\n",
    "    else:\n",
    "        S4=sum(scores)/len(scores)\n",
    "    NumOfFeatures = [r.n_selceted_feature for r in results if r.state==state]\n",
    "    if len(NumOfFeatures)==0:\n",
    "        S5=np.nan\n",
    "    else:\n",
    "        S5=sum(NumOfFeatures)/len(NumOfFeatures)       \n",
    "    NumOfRules = [r.n_selceted_feature for r in results if r.state==state]   \n",
    "    if len(NumOfRules)==0:\n",
    "        S6=np.nan\n",
    "    else:\n",
    "        S6=sum(NumOfRules)/len(NumOfRules)\n",
    "        \n",
    "    new_row = {'State':state, 'Train Acc':round(S1*100,2), 'Test Acc':round(S2*100,2), 'Train AUC':round(S3*100,2), 'Test AUC':round(S4*100,2), '# Featuress':S5, '# Rules':S6}\n",
    "    DF_results = DF_results.append(new_row, ignore_index=True) \n",
    "  # print('\\n'+ state + '....')\n",
    "  # print('Average Score_train: {}'.format(S1) + '  Average Score_test : {}'.format(S2) + '  NumOfFeatures : {}'.format(S3))\n",
    "    return DF_results\n",
    "\n",
    "def MakeDF(data_array,old_df,cols):\n",
    "    # cols = old_df.columns[selector.get_support()]\n",
    "    new_df = pd.DataFrame(data_array, index=old_df.index, columns=cols)\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5-26ByJFcHLR"
   },
   "source": [
    "**Train Method**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-21T07:28:48.596695Z",
     "start_time": "2021-02-21T07:28:48.416058Z"
    },
    "id": "48OAkPTeBzZ3"
   },
   "outputs": [],
   "source": [
    "%%capture cap --no-stdout\n",
    "def Trainning(X_train,X_test,y_train,y_test,clf,state):\n",
    "    clf=clf.fit(X_train,y_train)\n",
    "    Score_train=clf.score(X_train,y_train)\n",
    "    predicted_train=clf.predict(X_train)\n",
    "    AUC_train= roc_auc_score(y_train, predicted_train)\n",
    "    \n",
    "    Score_test=clf.score(X_test,y_test)\n",
    "    predicted_test=clf.predict(X_test)\n",
    "    AUC_test = roc_auc_score(y_test, predicted_test)\n",
    "\n",
    "# print(\"Initial Train ACC = \",Score_train)\n",
    "#   fpr, tpr, thresholds = metrics.roc_curve(y_test, predicted_test)\n",
    "#   AUC_test = auc(fpr, tpr)\n",
    "  # print(\"Initial Test ACC = \",Score_test)   \n",
    "  # print('AUC: %.2f' % AUC)\n",
    "    if state== 'Fuzzy':\n",
    "        print('Number Of Rules: ', len(clf.RB))\n",
    "        return  Result(Score_train,Score_test,AUC_train,AUC_test,X_train.shape[1],len(clf.RB),state)\n",
    "    else: \n",
    "        return  Result(Score_train,Score_test,AUC_train,AUC_test,X_train.shape[1],state)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D8ZwEThXMAkI"
   },
   "source": [
    "# **-----Read Data-----**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-21T07:28:48.746375Z",
     "start_time": "2021-02-21T07:28:48.600695Z"
    },
    "id": "Or2tg5ERcEY-"
   },
   "outputs": [],
   "source": [
    "def ReadData(Path_data, Path_label):\n",
    "    #X, y = load_iris(return_X_y = True)\n",
    "    df=pd.read_csv(Path_data)\n",
    "    df_y=pd.read_csv(Path_label)\n",
    "    X=df.iloc[:, 1:-1]\n",
    "    y=df_y.iloc[:, 2].replace('Non.cancer', 0).replace('NSCLC', 1)\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pct5JcL2L274"
   },
   "source": [
    "# **1) Normalization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-21T07:28:48.926867Z",
     "start_time": "2021-02-21T07:28:48.748379Z"
    },
    "id": "5qLvOdfxZOXU"
   },
   "outputs": [],
   "source": [
    "def Normalization(X_train,X_test):\n",
    "  ## 1.Scaling features to a range [0,1]\n",
    "  ## 2.Standardize features by removing the mean (u=0) and scaling to the same variance,z = (x - u) / s\n",
    "  scaler = MinMaxScaler().fit(X_train)\n",
    "  #scaler = StandardScaler(with_mean=False).fit(X_train)\n",
    "  X_train_new=scaler.transform(X_train)\n",
    "  X_test_new=scaler.transform(X_test)\n",
    "  selected_cols=X_train.columns\n",
    "  return MakeDF(X_train_new,X_train,selected_cols),MakeDF(X_test_new,X_test,selected_cols)   #return train_df,test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-LQw0IUeLxPU"
   },
   "source": [
    "# **2) FS: K Best**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-21T07:28:49.079988Z",
     "start_time": "2021-02-21T07:28:48.928869Z"
    },
    "id": "ym_kufAAam7W"
   },
   "outputs": [],
   "source": [
    "def KBestFS(X_train , X_test, metric_of_KBest, k_KBest):\n",
    "  selector = SelectKBest(metric_of_KBest, k=k_KBest)  \n",
    "  X_train_new=selector.fit(X_train, y_train).transform(X_train)\n",
    "  X_test_new=selector.transform(X_test)\n",
    "  selected_cols=X_train.columns.values[selector.get_support()]\n",
    "  return MakeDF(X_train_new,X_train,selected_cols),MakeDF(X_test_new,X_test,selected_cols)   #return train_df,test_df\n",
    "\n",
    "def KBestFS_Iterative(X_train,X_test,metric_of_KBest):\n",
    "        clf = LogisticRegression( solver='sag', multi_class='multinomial',penalty='l2')\n",
    "        k_KBest=X_train.shape[1]\n",
    "        X_train_old,X_test_old=KBestFS(X_train,X_test,metric_of_KBest,k_KBest)\n",
    "        result=Trainning(X_train_old,X_test_old,y_train,y_test,clf,'SelectKBest_'+str(k_KBest))\n",
    "        old_measure=result.Score_train\n",
    "        \n",
    "        while True:\n",
    "#             print('k_KBest '+str(k_KBest))\n",
    "#             print('old_measure '+str(old_measure))\n",
    "            k_old = k_KBest\n",
    "            k_KBest=math.floor(k_KBest/2)\n",
    "            X_train_new,X_test_new=KBestFS(X_train_old,X_test_old,metric_of_KBest,k_KBest)\n",
    "            result=Trainning(X_train_new,X_test_new,y_train,y_test,clf,'SelectKBest_'+str(k_KBest))\n",
    "            new_measure=result.Score_train\n",
    "            \n",
    "            if (abs(new_measure-old_measure)>=0.02): \n",
    "                break\n",
    "            else :\n",
    "                old_measure=new_measure\n",
    "                X_train_old,X_test_old=X_train_new,X_test_new\n",
    "            \n",
    "        k_KBest=k_old\n",
    "        \n",
    "        while True:\n",
    "#             print('k_KBest '+str(k_KBest))\n",
    "#             print('old_measure '+str(old_measure))\n",
    "            k_KBest=k_KBest-100\n",
    "            X_train_new,X_test_new=KBestFS(X_train_old,X_test_old,metric_of_KBest,k_KBest)\n",
    "            result=Trainning(X_train_new,X_test_new,y_train,y_test,clf,'SelectKBest_'+str(k_KBest))\n",
    "            new_measure=result.Score_train\n",
    "            \n",
    "            if (abs(new_measure-old_measure)>=0.01): \n",
    "                break\n",
    "            else :\n",
    "                old_measure=new_measure\n",
    "                X_train_old,X_test_old=X_train_new,X_test_new     \n",
    "                \n",
    "                \n",
    "        return X_train_old,X_test_old \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N2lKRY2MI2xX"
   },
   "source": [
    "# **3) FS: SelectFromModel**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-21T07:28:49.315705Z",
     "start_time": "2021-02-21T07:28:49.086988Z"
    },
    "id": "tnw33opv9d1C"
   },
   "outputs": [],
   "source": [
    "def ByModelFS(X_train , X_test):\n",
    "  selector = SelectFromModel(estimator)  \n",
    "  X_train_new=selector.fit(X_train, y_train).transform(X_train)\n",
    "  X_test_new=selector.transform(X_test)\n",
    "  selected_cols=X_train.columns.values[selector.get_support()]\n",
    "  return MakeDF(X_train_new,X_train,selected_cols),MakeDF(X_test_new,X_test,selected_cols)   #return train_df,test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y2Hwo-PTLrjL"
   },
   "source": [
    "# **4) FS: RFE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-21T07:28:49.497909Z",
     "start_time": "2021-02-21T07:28:49.327707Z"
    },
    "id": "1vd3AcPxDWcc"
   },
   "outputs": [],
   "source": [
    "def RFE_FS(X_train , X_test, n_final_features_to_select, step_REF):\n",
    "  selector = RFE(estimator, n_final_features_to_select, step=step_REF)\n",
    "  X_train_new=selector.fit(X_train, y_train).transform(X_train)\n",
    "  X_test_new=selector.transform(X_test)\n",
    "  selected_cols=X_train.columns.values[selector.get_support()]\n",
    "  return MakeDF(X_train_new,X_train,selected_cols),MakeDF(X_test_new,X_test,selected_cols)   #return train_df,test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xflHzBh47ATS"
   },
   "source": [
    "# **5) HyperoptEstimator**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-21T07:28:49.673717Z",
     "start_time": "2021-02-21T07:28:49.500911Z"
    },
    "id": "V_KqBsXm3faM"
   },
   "outputs": [],
   "source": [
    "%%capture cap\n",
    "# Under Development......\n",
    "def Tuning_classifier(clf):\n",
    "  clf1 = HyperoptEstimator(classifier=clf,trial_timeout=300)\n",
    "  # print( clf1.best_model() )\n",
    "  return clf1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AJghw3_b8lc3"
   },
   "source": [
    "# **6) Fuzzy Implementation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FRBCS_Mine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-21T07:28:49.952988Z",
     "start_time": "2021-02-21T07:28:49.676720Z"
    },
    "id": "zi704N6Q8emM"
   },
   "outputs": [],
   "source": [
    "class FRBCS:\n",
    "  bins = []\n",
    "  ABC=[]\n",
    "  numOfLabels=3\n",
    "  RB=[]\n",
    "  def __init__(self,numOfLabels=3):\n",
    "    self.numOfLabels=numOfLabels\n",
    "    self.bins = [-0.1]\n",
    "    numChaumck=((self.getNumOfLabels()-2)*2+2)\n",
    "    self.partitionLenght = 1/numChaumck   # assumed all data are in [0,1]\n",
    "    self.bins.extend([x*self.partitionLenght for x in range(1,numChaumck,2)]+[1.1])\n",
    "    self.ABC=self.setMFsParams()\n",
    "    return\n",
    "  def getNumOfLabels(self):\n",
    "    return self.numOfLabels\n",
    "    \n",
    "  def getMFsBins(self):\n",
    "    return self.bins\n",
    "\n",
    "  def setMFsParams(self):    \n",
    "    ABC=[]\n",
    "    p=(1/((self.getNumOfLabels()-2)*2+2))*2\n",
    "    ABC.append([0-p,0,0+p])\n",
    "    for i in range(self.getNumOfLabels()-1):\n",
    "        a,b=ABC[i][1],ABC[i][2]\n",
    "        ABC.append([a,b,b+p])\n",
    "    return ABC\n",
    "\n",
    "  def getMFsParams(self):     \n",
    "    return self.ABC\n",
    "  \n",
    "  def findLabel(self,value):\n",
    "    label=np.digitize(value, self.bins, right=True)\n",
    "    return label\n",
    "            \n",
    "  def transformToFuzzyLabels(self, X_train,y_train):     \n",
    "    df=X_train.copy()\n",
    "    for col in df.columns:\n",
    "      df[str(col)+\"_Fu\"] = df[col].map(lambda a: self.findLabel(a))\n",
    "      df = df.drop(col, 1)     \n",
    "    df=df.drop(df.std()[(df.std() == 0)].index, axis=1)   # remove column with totatally same lable\n",
    "    df['Antecedants'] = df.values.tolist()   # combine Labels\n",
    "    df['Label']=y_train.copy()                 \n",
    "    df['AntecedantsLabel'] = df.apply(lambda x: x['Antecedants']+ [x['Label']],axis = 1) # combine Labels\n",
    "    return df\n",
    "\n",
    "  def generateRules(self,df):\n",
    "        df=df.groupby(df['AntecedantsLabel'].map(tuple),as_index =False).agg(Antecedants=('Antecedants','first'),Label=('Label','first'),SP=('AntecedantsLabel','count'),Rules=('AntecedantsLabel','first'))\n",
    "        df = df[df.groupby(df['Antecedants'].map(tuple))['SP'].transform(max) == df['SP']]\n",
    "        return  df\n",
    "\n",
    "  def fit(self,X_train,y_train):\n",
    "        X_train_fuzzy=self.transformToFuzzyLabels(X_train,y_train)\n",
    "        df=X_train_fuzzy.copy()\n",
    "        self.RB=self.generateRules(df)\n",
    "        return  self   \n",
    "    \n",
    "  def score(self,X,y_actual):\n",
    "        y_predict=self.predict(X)\n",
    "#         print(y_predict)\n",
    "#         y_predict=y_actual\n",
    "        score=accuracy_score(y_actual, y_predict, normalize=True)\n",
    "        return score\n",
    "    \n",
    "  def trimMf(self,z,mf_ind):\n",
    "            a,b,c=self.ABC[mf_ind-1][0],self.ABC[mf_ind-1][1],self.ABC[mf_ind-1][2]\n",
    "            if (z<=a) or (z>=c):\n",
    "                y = 0\n",
    "            elif (a <= z <= b):\n",
    "                y = (z-a) / (b-a)\n",
    "            elif (b <= z <= c):\n",
    "                y = (c-z) / (c-b)\n",
    "            return y\n",
    "\n",
    "  def ClacMFValue(self,rule_Ant,X_row_val):\n",
    "    mul=1\n",
    "    for mf_ind, val in zip(rule_Ant, X_row_val):\n",
    "        mul=mul*self.trimMf(val,mf_ind)\n",
    "        if mul==0:\n",
    "           return 0\n",
    "    return mul   \n",
    "    \n",
    "  def classify(self,X_row_val):\n",
    "        MFs=self.RB.apply(lambda rule: [self.ClacMFValue(rule['Antecedants'],X_row_val),rule['Label']], axis=1)\n",
    "        predicted_label= max(MFs, key=lambda c: c[0])\n",
    "        return predicted_label[1]\n",
    "    \n",
    "  def predict(self,X):      \n",
    "      y=X.apply(lambda x: self.classify(x), axis=1)\n",
    "      return y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ChiRWClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-21T07:28:50.548725Z",
     "start_time": "2021-02-21T07:28:49.958994Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import sys\n",
    "import os\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path+\"\\\\Implementation\\\\ChiFRBCSPy\")\n",
    "    \n",
    "from ChiRWClassifier import ChiRWClassifier\n",
    "  \n",
    "def Traing_Chi_Alberto(X_tr,X_tst,y_tr,y_tst,state):\n",
    "\n",
    "    start_time = time.time()\n",
    "    chi = ChiRWClassifier(frm=\"wr\")\n",
    "\n",
    "    chi=chi.fit(X_tr,y_tr)\n",
    "    y_pred = chi.predict(X_tr)\n",
    "    Score_train=accuracy_score(y_tr,y_pred)\n",
    "    print(\"The accuracy of Chi-FRBCS model (train) is: \",Score_train )\n",
    "    y_pred = chi.predict(X_tst)\n",
    "    Score_test=accuracy_score(y_tst,y_pred)\n",
    "    print(\"The accuracy of Chi-FRBCS model (test) is: \", Score_test)\n",
    "\n",
    "    #Only for two-class problems\n",
    "    probas_ = chi.predict_proba(X_tr)\n",
    "    fpr, tpr, thresholds = roc_curve(y_tr, probas_[:, 1])\n",
    "    AUC_train = auc(fpr, tpr)\n",
    "    print(\"The AUC of Chi-FRBCS model  (train) es: \", AUC_train)\n",
    "    \n",
    "    \n",
    "    probas_ = chi.predict_proba(X_tst)\n",
    "    fpr, tpr, thresholds = roc_curve(y_tst, probas_[:, 1])\n",
    "    AUC_test = auc(fpr, tpr)\n",
    "    print(\"The AUC of Chi-FRBCS model  (test) es: \", AUC_test)\n",
    "    \n",
    "    NumberofRules=len(chi.kb.ruleBase)\n",
    "\n",
    "    t_exec = time.time() - start_time\n",
    "    hours = int(t_exec / 3600);\n",
    "    rest = t_exec % 3600;\n",
    "    minutes = int(rest / 60);\n",
    "    seconds = rest % 60;\n",
    "\n",
    "    print(\"Execution Time: \", hours , \":\" , minutes , \":\" , '{0:.4g}'.format(seconds))\n",
    "    return  Result(Score_train,Score_test,AUC_train,AUC_test,X_train.shape[1],NumberofRules,state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KrFv42PZeeA4"
   },
   "source": [
    "# **7) Trying a Genetic FS ...**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-21T07:28:50.573738Z",
     "start_time": "2021-02-21T07:28:50.554725Z"
    },
    "id": "dkmM1gogdTvP"
   },
   "outputs": [],
   "source": [
    "# is not good enough yet....\n",
    "def Trainning_GA(X_train,y_train,clf):\n",
    "  clf.fit(X_train,y_train)\n",
    "  Score_train=clf.score(X_train,y_train)\n",
    "  return  Score_train\n",
    "\n",
    "def f(X):\n",
    "  # print(X)\n",
    "  X_tra=X_train.copy()\n",
    "  l_initial=X_train.shape[1]\n",
    "\n",
    "  X_tra=X_tra.loc[:,X==1]\n",
    "  l=X_tra.shape[1]\n",
    "  print(l)\n",
    "  s=Trainning_GA(X_tra,y_train,clf)\n",
    "  print(s)\n",
    "  return (l/l_initial)+s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NMUN8ELacM6q"
   },
   "source": [
    "# Trying SKMoefs (P.Ducange 2014)...\n",
    "https://github.com/GionatanG/skmoefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-21T07:29:09.168005Z",
     "start_time": "2021-02-21T07:28:50.578742Z"
    }
   },
   "outputs": [],
   "source": [
    "#%%capture cap\n",
    "\n",
    "# import sys\n",
    "# sys.path.append(\"C:/Users/MASNA.CO/skmoefs/skmoefs\")\n",
    "\n",
    "from platypus.algorithms import *\n",
    "from skmoefs.toolbox import MPAES_RCS, load_dataset, normalize\n",
    "from skmoefs.rcs import RCSInitializer, RCSVariator\n",
    "from skmoefs.discretization.discretizer_base import fuzzyDiscretization\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def CreatDatFile(X,y,datastName):\n",
    "    df=X.copy()\n",
    "    df['Class']=y.copy()\n",
    "    f=open('dataset/' + datastName +'.dat', 'w')\n",
    "    f.write('@relation '+datastName +'\\n')\n",
    "    inputs=[]\n",
    "    line2=\"\"\n",
    "    for col in X.columns:\n",
    "        line='@attribute '+ col +' real ' +'['+ str(X[col].values.min()) +','+ str(X[col].values.max())+']\\n'\n",
    "        line2= line2+ str(col)+', '      \n",
    "        f.write(line) \n",
    "        \n",
    "    line='@attribute Class'+' integer ' +'{'+ str(y.min()) +','+ str(y.max())+'}\\n'\n",
    "\n",
    "    f.write(line)\n",
    "    f.write('@inputs '+line2+'\\n') \n",
    "    f.write('@outputs Class\\n@data\\n') \n",
    "    df.to_csv(f,index=False, header=False)\n",
    "    return \n",
    "\n",
    "def TrainMOEA(X_train,y_train,X_test,y_test,foldNumber,state,max_Evals):\n",
    "    dataset_Tra_Name='GeneExpre_Tra_'+str(foldNumber)\n",
    "    CreatDatFile(X_train,y_train,dataset_Tra_Name)\n",
    "    X_Tra, y_Tra, attributes, inputs, outputs = load_dataset(dataset_Tra_Name)  #iris\n",
    "    Xtr, ytr = normalize(X_Tra, y_Tra, attributes)\n",
    "\n",
    "    dataset_Tst_Name='GeneExpre_Tst_'+str(foldNumber)\n",
    "    CreatDatFile(X_test,y_test,dataset_Tst_Name)\n",
    "    X_Tst, y_Tst, attributes, inputs, outputs = load_dataset(dataset_Tst_Name)  #iris\n",
    "    Xte, yte = normalize(X_Tst, y_Tst, attributes)\n",
    "\n",
    "    my_moefs = MPAES_RCS(variator=RCSVariator(), initializer=RCSInitializer())\n",
    "    my_moefs.fit(Xtr, ytr, max_evals=max_Evals)\n",
    "\n",
    "    # my_moefs.show_pareto()\n",
    "    # my_moefs.show_pareto(Xte, yte)\n",
    "    # my_moefs.show_model('median', inputs=inputs, outputs=outputs)\n",
    "    scores_train=my_moefs.score(Xtr, ytr)\n",
    "    scores_test=my_moefs.score(Xte, yte)\n",
    "\n",
    "    Score_train = max(scores_train, key=lambda x:x[0])[0]  #0 accuracy  1 auc   2 trl\n",
    "    Score_test= max(scores_test, key=lambda x:x[0])[0]  #0 accuracy  1 auc   2 trl\n",
    "    AUC_train = max(Score_train, key=lambda x:x[1])[1]\n",
    "    AUC_test = max(scores_test, key=lambda x:x[1])[1]\n",
    "#     print(type(Score_train))\n",
    "#     print(Score_test)\n",
    "#     print(AUC)\n",
    "\n",
    "    return  Result(Score_train,Score_test,AUC_test,AUC_test ,X_train.shape[1],state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t2V_uAeWfEgi"
   },
   "source": [
    "# **-----Running-----**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-02-21T07:28:45.182Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iwjyF7HDG6SS",
    "outputId": "6647cd57-5c03-42bb-a186-4ed44ed8cbba",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 1 is processing...\n",
      "Number Of Rules:  35\n",
      "Initializing classifier:\n",
      "\n",
      "Rule Generation\n",
      "Computing Matching Degrees Rule\n",
      "Computing Matching Degrees All\n",
      "Computing Rule Weights\n",
      "Rule found: IF  10000 THEN 1 RW: 0.38796513450529585\n",
      "Rule found: IF  11001 THEN 0 RW: 0.17628032850191147\n",
      "Rule found: IF  01001 THEN 0 RW: 0.48192034542515483\n",
      "Rule found: IF  01101 THEN 0 RW: 0.2975283490581382\n",
      "Rule found: IF  11000 THEN 1 RW: 0.10124935629877235\n",
      "Rule found: IF  00000 THEN 0 RW: 0.0013727563294688122\n",
      "Rule found: IF  01000 THEN 0 RW: 0.280754423915537\n",
      "Rule found: IF  00001 THEN 0 RW: 0.2560569621683724\n",
      "Rule found: IF  00100 THEN 1 RW: 0.4214552880741242\n",
      "Rule found: IF  00011 THEN 0 RW: 0.6983841307625894\n",
      "Rule found: IF  00101 THEN 1 RW: 0.11485270661189682\n",
      "Rule found: IF  02001 THEN 0 RW: 0.7950011802870268\n",
      "Rule found: IF  00010 THEN 0 RW: 0.5649112936268993\n",
      "Rule found: IF  01002 THEN 0 RW: 0.9026022746662498\n",
      "Rule found: IF  00110 THEN 0 RW: 0.033392206378854206\n",
      "Rule found: IF  10011 THEN 0 RW: 0.4131159966408178\n",
      "Rule found: IF  11002 THEN 0 RW: 0.8771208775214147\n",
      "Rule found: IF  00111 THEN 0 RW: 0.26097723943457163\n",
      "Rule found: IF  01110 THEN 0 RW: 0.38653530827353555\n",
      "Rule found: IF  00120 THEN 0 RW: 0.652030949357368\n",
      "Rule found: IF  01100 THEN 0 RW: 0.01774719406291589\n",
      "Rule found: IF  00102 THEN 0 RW: 0.9507850743200686\n",
      "Rule found: IF  10101 THEN 1 RW: 0.5822562139299396\n",
      "Rule found: IF  10100 THEN 1 RW: 0.6910536784035199\n",
      "Rule found: IF  11101 THEN 1 RW: 0.23471640003988428\n",
      "Rule found: IF  10001 THEN 1 RW: 0.2466727772292507\n",
      "Rule found: IF  11110 THEN 0 RW: 0.025340530606713426\n",
      "Rule found: IF  11100 THEN 1 RW: 0.4547438628576958\n",
      "Rule found: IF  20100 THEN 1 RW: 0.9848145448354597\n",
      "Rule found: IF  20200 THEN 1 RW: 1.0\n",
      "Rule found: IF  00200 THEN 1 RW: 0.9856344241709548\n",
      "Rule found: IF  10200 THEN 1 RW: 0.9821608602231773\n",
      "Rule found: IF  21101 THEN 1 RW: 0.8203316119438524\n",
      "Rule found: IF  10111 THEN 1 RW: 0.125469257021774\n",
      "Rule Base: 34\n",
      "The accuracy of Chi-FRBCS model (train) is:  0.78330658105939\n",
      "The accuracy of Chi-FRBCS model (test) is:  0.717948717948718\n",
      "The AUC of Chi-FRBCS model  (train) es:  0.8547390676567655\n",
      "The AUC of Chi-FRBCS model  (test) es:  0.791529334212261\n",
      "Execution Time:  0 : 0 : 1.531\n",
      "fold 2 is processing...\n"
     ]
    }
   ],
   "source": [
    "%%capture cap --no-stdout\n",
    "results=[]\n",
    "\n",
    "X,y = ReadData(Path_data, Path_label)\n",
    "\n",
    "cv= KFold(n_folds, random_state=42, shuffle=True)  #KFold, StratifiedKFold to be check?\n",
    "i=1\n",
    "for train_index, test_index in cv.split(X):\n",
    "\n",
    "    print('fold '+str(i)+' is processing...')\n",
    "    i=i+1\n",
    "    X_train,X_test,y_train,y_test=X.iloc[train_index,:],X.iloc[test_index,:],y.iloc[train_index],y.iloc[test_index]\n",
    "\n",
    "    result=Trainning(X_train,X_test,y_train,y_test,clf,'Initialization')\n",
    "    results.append(result)\n",
    "\n",
    "    X_train,X_test=Normalization(X_train,X_test)\n",
    "    result=Trainning(X_train,X_test,y_train,y_test,clf,'Normalization')\n",
    "    results.append(result)\n",
    "\n",
    "#     X_train,X_test=KBestFS(X_train,X_test,metric_of_KBest,k_KBest)\n",
    "    X_train,X_test=KBestFS_Iterative(X_train,X_test,metric_of_KBest)\n",
    "    result=Trainning(X_train,X_test,y_train,y_test,clf,'SelectKBest')\n",
    "    results.append(result)\n",
    "\n",
    "    X_train,X_test=ByModelFS(X_train,X_test)\n",
    "    result=Trainning(X_train,X_test,y_train,y_test,clf,'SelectFromModel')\n",
    "    results.append(result)\n",
    "\n",
    "    X_train,X_test=RFE_FS(X_train , X_test, n_final_features_to_select, step_REF)\n",
    "    result=Trainning(X_train,X_test,y_train,y_test,clf,'RFE_FS')\n",
    "    results.append(result)\n",
    "\n",
    "    # model=ga(function=f,dimension=X_train.shape[1],variable_type='bool',algorithm_parameters=algorithm_param)\n",
    "    # model=ga(function=f,dimension=X_train.shape[1],variable_type='bool')\n",
    "    # model.run()\n",
    "\n",
    "#     clf1=Tuning_classifier(clf)\n",
    "#     result=Trainning(X_train,X_test,y_train,y_test,clf1,'Tuning_classifier')\n",
    "#     results.append(result)\n",
    "\n",
    "    frbcs_clf=FRBCS(numOfLabels=3).fit(X_train,y_train)\n",
    "    result=Trainning(X_train,X_test,y_train,y_test,frbcs_clf,'Fuzzy')\n",
    "    results.append(result)\n",
    "    \n",
    "    result=Traing_Chi_Alberto(X_train,X_test,y_train,y_test,'Fuzzy_alberto')\n",
    "    results.append(result)\n",
    "    \n",
    "#     result= TrainMOEA(X_train,y_train,X_test,y_test,i-1,\"MPAES_RCS\",max_Evals)\n",
    "#     results.append(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-02-21T07:28:45.185Z"
    }
   },
   "outputs": [],
   "source": [
    "(34+39+28+45+39)/5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dAkO_lPqfexC"
   },
   "source": [
    "# **Show Results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-02-21T07:28:45.188Z"
    },
    "id": "bGkT2aM1nq28"
   },
   "outputs": [],
   "source": [
    "Results_df = pd.DataFrame(columns=['State', 'Train Acc', 'Test Acc','Train AUC','Test AUC','# Featuress','# Rules'])\n",
    "Results_df=PrintResults(results, 'Initialization',Results_df)\n",
    "Results_df=PrintResults(results, 'Normalization',Results_df)\n",
    "Results_df=PrintResults(results, 'SelectKBest',Results_df)\n",
    "Results_df=PrintResults(results, 'SelectFromModel',Results_df)\n",
    "Results_df=PrintResults(results, 'RFE_FS',Results_df)\n",
    "Results_df=PrintResults(results, 'Tuning_classifier',Results_df)\n",
    "Results_df=PrintResults(results, 'Fuzzy',Results_df)\n",
    "Results_df=PrintResults(results, 'Fuzzy_alberto',Results_df)\n",
    "Results_df=PrintResults(results, 'MPAES_RCS',Results_df)\n",
    "# Results_df.to_csv(\"./drive/MyDrive/Colab Notebooks/Results/RF_Results.csv\")\n",
    "Results_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-02-21T07:28:45.191Z"
    },
    "id": "tkzAC_kUY2ij"
   },
   "outputs": [],
   "source": [
    "## With RF as classifier\n",
    "# Results_df=pd.read_csv(\"./drive/MyDrive/Colab Notebooks/Results/RF_Results.csv\")\n",
    "# Results_df=Results_df.drop(columns=['Unnamed: 0']).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nLPWpXTAfWUE"
   },
   "source": [
    "# **Plotting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-02-21T07:28:45.194Z"
    },
    "id": "H1AKQ-uLmYIM"
   },
   "outputs": [],
   "source": [
    "g=sns.catplot(x=\"State\", y=\"Test Acc\",kind=\"point\", data=Results_df,color='r')\n",
    "g.set_xticklabels(label='',rotation=70,size=15)\n",
    "g.set(ylim=(70, 90))\n",
    "g.set_axis_labels(\"\",\"\")\n",
    "g.fig.suptitle('Trend of Test ACC', size=15,color='b')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_EIN3dT2e3c9"
   },
   "source": [
    "# ------------End of Pipeline----"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Test1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "320px",
    "width": "261px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "273.188px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
